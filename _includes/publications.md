<h2 id="publications" style="margin: 2px 0px -15px;">Recent Publications</h2>

<div class="publications">
<ol class="bibliography">

Please see the full publication list at <a href="https://scholar.google.com/citations?user=5VpkLO8AAAAJ&hl=en">Google Scholar</a>



<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="assets/img/doma.png" class="teaser img-fluid z-depth-1">
    <abbr class="badge">CVPR</abbr>
  </div>
  <div class="col-sm-9" style="position: relative;padding-right: 15px;padding-left: 20px;">
    <div class="title"><a href="https://arxiv.org/abs/2406.03625">Degrees of Freedom Matter: Inferring Dynamics from Point Trajectories</a></div>
    <div class="author"> <strong>Yan Zhang</strong>, Sergey Prokudin, Marko Mihajlovic, Qianli Ma, Siyu Tang</div>
    <div class="periodical"><em>IEEE/CVF Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong>, 2024.</em></div>
    <div style="font-size: 12px;color: red;"><em>A compact implicit motion field with spatiotemporal regularity.</em></div>
    <div class="links">
      <a href="https://arxiv.org/abs/2406.03625" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PDF</a>
      <a href="https://yz-cnsdqz.github.io/eigenmotion/DOMA/" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">Code</a>
      <a href="https://yz-cnsdqz.github.io/eigenmotion/DOMA/" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">Project Page</a>
    </div>
  </div>
</div>
</li>


<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="assets/img/egogen.png" class="teaser img-fluid z-depth-1">
    <abbr class="badge">CVPR</abbr>
  </div>
  <div class="col-sm-9" style="position: relative;padding-right: 15px;padding-left: 20px;">
    <div class="title"><a href="https://arxiv.org/abs/2401.08739">EgoGen: An Egocentric Synthetic Data Generator</a></div>
    <div class="author"> Gen Li, Kaifeng Zhao, Siwei Zhang, Xiaozhong Lyu, Mihai Dusmanu, <strong>Yan Zhang</strong>, Marc Pollefeys, Siyu Tang</div>
    <div class="periodical"><em>IEEE/CVF Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong>, 2024. <strong>(ORAL) </strong>  </em></div>
    <div style="font-size: 12px;color: red;"><em>A novel human motion synthesis model with egocentric visual perception. The effectiveness of rendered synthetic data is verified in various tasks.</em></div>
    <div class="links">
      <a href="https://arxiv.org/abs/2401.08739" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PDF</a>
      <a href="https://ego-gen.github.io" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">Code</a>
      <a href="https://ego-gen.github.io" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">Project Page</a>
    </div>
  </div>
</div>
</li>



<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="assets/img/egogen.png" class="teaser img-fluid z-depth-1">
    <abbr class="badge">CVPR</abbr>
  </div>
  <div class="col-sm-9" style="position: relative;padding-right: 15px;padding-left: 20px;">
    <div class="title"><a href="https://arxiv.org/abs/2403.10518">Lodge: A Coarse to Fine Diffusion Network for Long Dance Generation Guided by the Characteristic Dance Primitives</a></div>
    <div class="author"> Ronghui Li, YuXiang Zhang, Yachao Zhang, Hongwen Zhang, Jie Guo, <strong>Yan Zhang</strong>, Yebin Liu, Xiu Li</div>
    <div class="periodical"><em>IEEE/CVF Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong>, 2024. </em></div>
    <div style="font-size: 12px;color: red;"><em> A two-stage coarse-to-fine diffusion architecture capable of generating extremely long dance sequences based on music. Our characteristic dance primitives possess significant expressiveness as intermediate representations between the two diffusion models.</em></div>
    <div class="links">
      <a href="https://arxiv.org/abs/2403.10518" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PDF</a>
      <a href="https://li-ronghui.github.io/lodge" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">Code</a>
      <a href="https://li-ronghui.github.io/lodge" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">Project Page</a>
    </div>
  </div>
</div>
</li>


<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="assets/img/dimos.png" class="teaser img-fluid z-depth-1">
    <abbr class="badge">ICCV</abbr>
  </div>
  <div class="col-sm-9" style="position: relative;padding-right: 15px;padding-left: 20px;">
    <div class="title"><a href="https://arxiv.org/abs/2305.12411">Synthesizing Diverse Human Motions in 3D Indoor Scenes</a></div>
    <div class="author"> Kaifeng Zhao, <strong>Yan Zhang</strong>, Shaofei Wang, Thabo Beeler, Siyu Tang</div>
    <div class="periodical"><em>IEEE/CVF International Conference on Computer Vision <strong>(ICCV)</strong>, 2023.</em></div>
    <div style="font-size: 12px;color: red;"><em>Generative motion pritimives + RL to synthesize lifelike behavior in 3D scenes.</em></div>
    <div class="links">
      <a href="https://arxiv.org/abs/2305.12411" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PDF</a>
      <a href="https://zkf1997.github.io/DIMOS" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">Code</a>
      <a href="https://zkf1997.github.io/DIMOS" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">Project Page</a>
    </div>
  </div>
</div>
</li>




<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="assets/img/egohmr.jpg" class="teaser img-fluid z-depth-1">
    <abbr class="badge">ICCV</abbr>
  </div>
  <div class="col-sm-9" style="position: relative;padding-right: 15px;padding-left: 20px;">
    <div class="title"><a href="https://arxiv.org/abs/2304.06024">Probabilistic Human Mesh Recovery in 3D Scenes from Egocentric Views</a></div>
    <div class="author"> Siwei Zhang, Qianli Ma, <strong>Yan Zhang</strong>, Sadegh Aliakbarian, Darren Cosker, Siyu Tang</div>
    <div class="periodical"><em>IEEE/CVF International Conference on Computer Vision <strong>(ICCV)</strong>, 2023. <strong>(ORAL) </strong> </em></div>
    <div style="font-size: 12px;color: red;"><em>A scene-conditioned diffusion model regresses 3D bodies from single images. The denoising process guided by COAP solves interpenetration.</em></div>
    <div class="links">
      <a href="https://arxiv.org/abs/2304.06024" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PDF</a>
      <a href="https://sanweiliti.github.io/egohmr/egohmr.html" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">Code</a>
      <a href="https://sanweiliti.github.io/egohmr/egohmr.html" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">Project Page</a>
    </div>
  </div>
</div>
</li>




<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="assets/img/gamma.jpg" class="teaser img-fluid z-depth-1">
    <abbr class="badge">CVPR</abbr>
  </div>
  <div class="col-sm-9" style="position: relative;padding-right: 15px;padding-left: 20px;">
    <div class="title"><a href="https://arxiv.org/abs/2112.09251">The wanderings of odysseus in 3D scenes</a></div>
    <div class="author"><strong>Yan Zhang</strong>, Siyu Tang</div>
    <div class="periodical"><em>IEEE/CVF Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong>, 2022.</em></div>
    <div style="font-size: 12px;color: red;"><em>Generative motion pritimives + RL to synthesize locomotion behavior of diverse human identities. Featured at the homepage of ETH Zurich.</em></div>
    <div class="links">
      <a href="https://arxiv.org/abs/2112.09251" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PDF</a>
      <a href="https://github.com/yz-cnsdqz/GAMMA-release" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">Code</a>
      <a href="https://yz-cnsdqz.github.io/eigenmotion/GAMMA/" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">Project Page</a>
    </div>
  </div>
</div>
</li>
  


<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="assets/img/mojo.jpg" class="teaser img-fluid z-depth-1">
    <abbr class="badge">CVPR</abbr>
  </div>
  <div class="col-sm-9" style="position: relative;padding-right: 15px;padding-left: 20px;">
    <div class="title"><a href="https://arxiv.org/abs/2012.00619">We are More than Our Joints: Predicting how 3D Bodies Move</a></div>
    <div class="author"><strong>Yan Zhang</strong>, Michael J. Black, Siyu Tang</div>
    <div class="periodical"><em>IEEE/CVF Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong>, 2021.</em></div>
    <div style="font-size: 12px;color: red;"><em>A novel marker-based body representation for stochastic motion prediction. </em></div>
    <div class="links">
      <a href="https://arxiv.org/abs/2112.09251" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PDF</a>
      <a href="https://github.com/yz-cnsdqz/MOJO-release" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">Code</a>
      <a href="https://yz-cnsdqz.github.io/eigenmotion/MOJO/index.html" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">Project Page</a>
    </div>
  </div>
</div>
</li>
  


<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="assets/img/psi.png" class="teaser img-fluid z-depth-1">
    <abbr class="badge">CVPR</abbr>
  </div>
  <div class="col-sm-9" style="position: relative;padding-right: 15px;padding-left: 20px;">
    <div class="title"><a href="https://arxiv.org/abs/1912.02923">Generating 3d people in scenes without people</a></div>
    <div class="author"><strong>Yan Zhang</strong>, Mohamed Hassan, Heiko Neumann, Michael J Black, Siyu Tang</div>
    <div class="periodical"><em>IEEE/CVF Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong>, 2020 <strong>(ORAL) </strong>.</em></div>
    <div style="font-size: 12px;color: red;"><em>generative model to populate scenes + test-time optimization </em></div>
    <div class="links">
      <a href="https://arxiv.org/abs/1912.02923" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PDF</a>
      <a href="https://github.com/yz-cnsdqz/PSI-release" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">Code</a>
      <a href="https://ps.is.mpg.de/publications/smpl-x-conditional-vae-prox-scene-constraints" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">Project Page</a>
    </div>
  </div>
</div>
</li>



<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="assets/img/finegrainedseg.png" class="teaser img-fluid z-depth-1">
    <abbr class="badge">CVPR</abbr>
  </div>
  <div class="col-sm-9" style="position: relative;padding-right: 15px;padding-left: 20px;">
    <div class="title"><a href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Local_Temporal_Bilinear_Pooling_for_Fine-Grained_Action_Parsing_CVPR_2019_paper.html">Local temporal bilinear pooling for fine-grained action parsing</a></div>
    <div class="author"><strong>Yan Zhang</strong>, Siyu Tang, Krikamol Muandet, Christian Jarvers, Heiko Neumann</div>
    <div class="periodical"><em>IEEE/CVF Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong>, 2019.</em></div>
    <div style="font-size: 12px;color: red;"><em>A novel plug-in bilinear pooling layer for fine-grained action segmentation. </em></div>
    <div class="links">
      <a href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Local_Temporal_Bilinear_Pooling_for_Fine-Grained_Action_Parsing_CVPR_2019_paper.html" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PDF</a>
      <a href="https://github.com/yz-cnsdqz/TemporalActionParsing-FineGrained" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">Code</a>
      <a href="https://ps.is.mpg.de/publications/bilinear2018" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">Project Page</a>
    </div>
  </div>
</div>
</li>


<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="assets/img/egobody.png" class="teaser img-fluid z-depth-1">
    <abbr class="badge">ECCV</abbr>
  </div>
  <div class="col-sm-9" style="position: relative;padding-right: 15px;padding-left: 20px;">
    <div class="title"><a href="https://arxiv.org/pdf/2112.07642.pdf">Egobody: Human body shape and motion of interacting people from head-mounted devices</a></div>
    <div class="author">Siwei Zhang, Qianli Ma, <strong>Yan Zhang</strong>, Zhiyin Qian, Taein Kwon, Marc Pollefeys, Federica Bogo & Siyu Tang </div>
    <div class="periodical"><em>European Conference on Computer Vision <strong>(ECCV)</strong>, 2022.</em></div>
    <div style="font-size: 12px;color: red;"><em>A dataset of people interactions in 3D scenes, captured by Kinects and Hololens. </em></div>
    <div class="links">
      <a href="https://arxiv.org/pdf/2112.07642.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PDF</a>
      <a href="https://github.com/sanweiliti/EgoBody" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">Code</a>
      <a href="https://github.com/sanweiliti/EgoBody" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">Project Page</a>
    </div>
  </div>
</div>
</li>


<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="assets/img/lemo.jpg" class="teaser img-fluid z-depth-1">
    <abbr class="badge">ICCV</abbr>
  </div>
  <div class="col-sm-9" style="position: relative;padding-right: 15px;padding-left: 20px;">
    <div class="title"><a href="https://openaccess.thecvf.com/content/ICCV2021/html/Zhang_Learning_Motion_Priors_for_4D_Human_Body_Capture_in_3D_ICCV_2021_paper.html">Learning motion priors for 4d human body capture in 3d scenes</a></div>
    <div class="author">Siwei Zhang, <strong>Yan Zhang</strong>, Federica Bogo, Marc Pollefeys, Siyu Tang </div>
    <div class="periodical"><em>IEEE/CVF International Conference on Computer Vision <strong>(ICCV)</strong>, 2021 <strong>(ORAL) </strong>.</em></div>
    <div style="font-size: 12px;color: red;"><em>Marker motion priors to capture body motions in 3D scenes. </em></div>
    <div class="links">
      <a href="https://openaccess.thecvf.com/content/ICCV2021/html/Zhang_Learning_Motion_Priors_for_4D_Human_Body_Capture_in_3D_ICCV_2021_paper.html" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PDF</a>
      <a href="https://sanweiliti.github.io/LEMO/LEMO.html" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">Code</a>
      <a href="https://github.com/sanweiliti/LEMO" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">Project Page</a>
    </div>
  </div>
</div>
</li>



<br>



</ol>
</div>
